{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0f461a",
   "metadata": {},
   "source": [
    "# Rede de citação\n",
    "Dados do dataset 2020 que tenham relação com pelo menos uma das vacinas Coronavac,Astrazeneca,Moderna,Janssen e Pfizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a53221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar pycairo, igraph e depois importar bibliotecas\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pandas as pd \n",
    "import csv\n",
    "import math\n",
    "from igraph import Graph, plot\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4b02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\Jupyter Notebook\\COVID19Dataset\\metadata.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b4051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de artigos DFFinalizado: 66\n",
      "Número de artigos DFNotNA: 325855\n"
     ]
    }
   ],
   "source": [
    "# Cria uma cópia do DataFrame original e remove linhas onde 'abstract' é nulo\n",
    "df_notna_aux1 = df.copy()\n",
    "df_notna_aux1 = df_notna_aux1[df_notna_aux1['abstract'].notna()]\n",
    "\n",
    "# Remove linhas onde 'authors' é nulo\n",
    "df_notna_aux2 = df_notna_aux1.copy()\n",
    "df_notna_aux2 = df_notna_aux2[df_notna_aux2['authors'].notna()]\n",
    "\n",
    "# Remove linhas onde 'publish_time' é nulo\n",
    "df_notna_aux3 = df_notna_aux2.copy()\n",
    "df_notna_aux3 = df_notna_aux3[df_notna_aux3['publish_time'].notna()]\n",
    "\n",
    "# Remove linhas onde 'pdf_json_files' é nulo\n",
    "df_notna = df_notna_aux3.copy()\n",
    "df_notna = df_notna[df_notna['pdf_json_files'].notna()]\n",
    "\n",
    "# Converte o formato de 'publish_time' para datetime\n",
    "df_notna['publish_time'] = pd.to_datetime(df_notna['publish_time'])\n",
    "\n",
    "# Filtra o ano de 2020\n",
    "df_ano = df_notna[(df_notna['publish_time'] >= '2020-01-01 00:00:00') & (df_notna['publish_time'] <= '2021-01-01 00:00:00')]\n",
    "\n",
    "# Filtra por nomes de pelo menos uma das vacinas\n",
    "df_vacina = df_ano[df_ano['abstract'].str.contains(\"Coronavac|Astrazeneca|Moderna|Janssen|Pfizer\", case=False)]\n",
    "\n",
    "# Filtra os artigos onde o campo 'title' não é nulo\n",
    "df_finalizado = df_vacina[df_vacina['title'].notna()]\n",
    "\n",
    "print(\"Número de artigos DFFinalizado:\", len(df_finalizado))\n",
    "print(\"Número de artigos DFNotNA:\", len(df_notna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d92df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui é feita a união de caminho de diretório de forma portável, armazenando os caminhos completos em uma lista\n",
    "datafiles = []\n",
    "for filename in df_finalizado['pdf_json_files']:\n",
    "    ifile = os.path.join('..\\Jupyter Notebook\\COVID19Dataset', filename)\n",
    "    datafiles.append(ifile)\n",
    "    \n",
    "with open(datafiles[0],'r')as f:\n",
    "    doc = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4043ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "citbib = []\n",
    "\n",
    "for file in datafiles:\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            doc = json.load(f)\n",
    "        \n",
    "        id = doc['paper_id']\n",
    "        title = doc['metadata']['title']\n",
    "        \n",
    "        authors_doc = []\n",
    "        for author in doc['metadata']['authors']:\n",
    "            first = author['first']\n",
    "            middle = author.get('middle', None)\n",
    "            last = author['last']\n",
    "            suffix = author.get('suffix', None)\n",
    "            \n",
    "            affiliation = author.get('affiliation', {})\n",
    "            laboratory = affiliation.get('laboratory', None)\n",
    "            institution = affiliation.get('institution', None)\n",
    "            \n",
    "            location = affiliation.get('location', {})\n",
    "            settlement = location.get('settlement', None)\n",
    "            region = location.get('region', None)\n",
    "            country = location.get('country', None)\n",
    "            \n",
    "            email = author.get('email', None)\n",
    "            \n",
    "            authors_doc.append({\n",
    "                'first': first,\n",
    "                'middle': middle,\n",
    "                'last': last,\n",
    "                'suffix': suffix,\n",
    "                'affiliation': {\n",
    "                    'laboratory': laboratory,\n",
    "                    'institution': institution,\n",
    "                    'location': {\n",
    "                        'settlement': settlement,\n",
    "                        'region': region,\n",
    "                        'country': country\n",
    "                    }\n",
    "                },\n",
    "                'email': email\n",
    "            })\n",
    "        \n",
    "        bibEntries = []\n",
    "        for key, value in doc['bib_entries'].items():\n",
    "            refid = key\n",
    "            bib_title = value['title']\n",
    "            \n",
    "            authors_bib = []\n",
    "            for author in value['authors']:\n",
    "                first = author['first']\n",
    "                middle = author.get('middle', None)\n",
    "                last = author['last']\n",
    "                suffix = author.get('suffix', None)\n",
    "                \n",
    "                authors_bib.append({\n",
    "                    'first': first,\n",
    "                    'middle': middle,\n",
    "                    'last': last,\n",
    "                    'suffix': suffix\n",
    "                })\n",
    "            \n",
    "            year = value['year']\n",
    "            \n",
    "            try:\n",
    "                DOI = value['other_ids']['DOI'][0]\n",
    "            except KeyError:\n",
    "                DOI = np.nan\n",
    "            \n",
    "            bibEntries.append({\n",
    "                'refid_bib': refid,\n",
    "                'title': bib_title,\n",
    "                'authors_bib': authors_bib,\n",
    "                'year': year,\n",
    "                'DOI': DOI\n",
    "            })\n",
    "        \n",
    "        citbib.append({\n",
    "            'id': id,\n",
    "            'title': title,\n",
    "            'authors_doc': authors_doc,\n",
    "            'bib': bibEntries\n",
    "        })\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d7a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando em um csv\n",
    "df = pd.DataFrame(citbib)\n",
    "df.to_csv('citbib.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad84abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para remover caracteres desconhecidos\n",
    "def remove_unidentified_chars(text):\n",
    "    try:\n",
    "        text.encode('utf-8').decode('utf-8')\n",
    "        return text\n",
    "    except UnicodeDecodeError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffed40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapeamento de cada titulo para um ID único, já que os ids das citações se repetem para cada artigo, além da remoção de caracteres desconhecidos.\n",
    "title_mapping = {}\n",
    "current_id = 0\n",
    "\n",
    "for entry in citbib:\n",
    "    #remover caracteres não identificados\n",
    "    article_title = remove_unidentified_chars(entry['title']).strip()\n",
    "    if article_title: #verificação se não ficou vazio\n",
    "        if article_title not in title_mapping:\n",
    "            title_mapping[article_title] = current_id\n",
    "            current_id += 1\n",
    "\n",
    "    for bib_entry in entry['bib']:\n",
    "        bib_title = remove_unidentified_chars(bib_entry['title']).strip()\n",
    "        if bib_title:\n",
    "            if bib_title not in title_mapping:\n",
    "                title_mapping[bib_title] = current_id\n",
    "                current_id += 1\n",
    "\n",
    "#Salvando em um csv com \"id\" e \"title\" para futuras consultas\n",
    "with open('mapeamento.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['id', 'title']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for title, unique_id in title_mapping.items():\n",
    "        writer.writerow({'id': unique_id, 'title': title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19413967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percorrendo citbib e olhando os IDs de \"mapeamento\", relaciona o id do artigo com o idcitado.\n",
    "citations = {}\n",
    "\n",
    "for entry in citbib:\n",
    "    article_title = remove_unidentified_chars(entry['title']).strip()\n",
    "    if article_title:\n",
    "        title_id = title_mapping.get(article_title)\n",
    "        if title_id is not None:\n",
    "            if title_id not in citations:\n",
    "                citations[title_id] = set()  # set para não duplicar \n",
    "\n",
    "            for bib_entry in entry['bib']:\n",
    "                bib_title = remove_unidentified_chars(bib_entry['title']).strip()\n",
    "                if bib_title:\n",
    "                    # Obter o ID da entrada de bibliografia a partir do mapeamento\n",
    "                    bib_id = title_mapping.get(bib_title)\n",
    "                    if bib_id is not None:\n",
    "                        # Adicionar o ID da entrada de bibliografia ao conjunto de citações\n",
    "                        citations[title_id].add(bib_id)  \n",
    "\n",
    "# Salvar as citações em um arquivo CSV\n",
    "with open('citations.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['idTitle', 'idCit']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for title_id, bib_ids in citations.items():\n",
    "        for bib_id in bib_ids:\n",
    "            writer.writerow({'idTitle': title_id, 'idCit': bib_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e142a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {}\n",
    "with open('mapeamento.csv', 'r', encoding='utf-8') as csvfile:  \n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        title_mapping[int(row['id'])] = row['title']\n",
    "\n",
    "citations = []\n",
    "with open('citations.csv', 'r', encoding='utf-8') as csvfile:  \n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        citations.append((int(row['idTitle']), int(row['idCit'])))\n",
    "\n",
    "#Criando grafo direcionado, onde os nós são cada id em mapeamento e as ligações são as citações.\n",
    "grafo = ig.Graph(directed=True)\n",
    "\n",
    "grafo.add_vertices(len(title_mapping))\n",
    "\n",
    "grafo.add_edges(citations)\n",
    "\n",
    "#Atribuir label (imagem gerada é bem pesada)\n",
    "grafo.vs[\"label\"] = [title_mapping.get(node.index, \"\") for node in grafo.vs]\n",
    "\n",
    "layout = grafo.layout_fruchterman_reingold()\n",
    "#ig.plot(grafo, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410dabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No grafo acima, existem muitos nós não citados, então é criado um grafo com a exclusão dos nós sem ligações\n",
    "gCitacao = grafo.copy()\n",
    "\n",
    "#Verifica nós sem conexões (citações) e remove\n",
    "isolated_nodes = [v.index for v in gCitacao.vs if v.indegree() == 0 and v.outdegree() == 0]\n",
    "gCitacao.delete_vertices(isolated_nodes)\n",
    "\n",
    "layout = gCitacao.layout_fruchterman_reingold()\n",
    "#ig.plot(gCitacao, layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b356728",
   "metadata": {},
   "source": [
    "## Clusterização para atribuição de cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a333d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = []\n",
    "\n",
    "# Função para gerar uma cor aleatória em formato hexadecimal\n",
    "def cor_aleatoria():\n",
    "    r = random.randint(0, 255)\n",
    "    g = random.randint(0, 255)\n",
    "    b = random.randint(0, 255)\n",
    "    return \"#{:02X}{:02X}{:02X}\".format(r, g, b)\n",
    "\n",
    "# Gerar 185 cores aleatórias e adicioná-las à paleta (existem 183 nós no grafo de citações)\n",
    "for _ in range(185):\n",
    "    color_palette.append(cor_aleatoria())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2575a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algoritmo Walktrap para identificar os clusters no grafo direcionado\n",
    "dendrogram = gCitacaoDegree.community_walktrap()\n",
    "\n",
    "#Converter o dendrograma em um objeto de clustering\n",
    "clusters = dendrogram.as_clustering()\n",
    "\n",
    "#Obter a atribuição de cluster para cada nó\n",
    "membership = clusters.membership\n",
    "\n",
    "available_colors = color_palette.copy() \n",
    "cluster_to_color = {}\n",
    "\n",
    "#Atribuir cada cor para um cluster diferente, somente repetindo as cores se todas acabarem\n",
    "for cluster_num in set(membership):\n",
    "    if len(available_colors) > 0:\n",
    "        color = random.choice(available_colors)\n",
    "        available_colors.remove(color)\n",
    "    if len(available_colors) == 0:\n",
    "        available_colors = color_palette\n",
    "    cluster_to_color[cluster_num] = color\n",
    "\n",
    "# Definir as cores dos nós com base nos clusters\n",
    "gCitacaoDegree.vs[\"color\"] = [cluster_to_color[membership[node.index]] for node in gCitacaoDegree.vs]\n",
    "\n",
    "#Resultado\n",
    "layout = gCitacaoDegree.layout_fruchterman_reingold()\n",
    "#ig.plot(gCitacao, layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a099385",
   "metadata": {},
   "source": [
    "## Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55a1dff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Mínimo: 0.0\n",
      "Betweenness Máximo: 148.0\n"
     ]
    }
   ],
   "source": [
    "gCitacaoBetweenness = gCitacao.copy()\n",
    "# Calcule o betweenness\n",
    "betweenness = gCitacaoBetweenness.betweenness(vertices=None, directed=True, cutoff=None, weights=None)\n",
    "\n",
    "# Calcule o máximo e o mínimo do betweenness\n",
    "max_betweenness = max(betweenness)\n",
    "min_betweenness = min(betweenness)\n",
    "print(\"Betweenness Mínimo:\", min_betweenness)\n",
    "print(\"Betweenness Máximo:\", max_betweenness)\n",
    "\n",
    "# Aplique a escala de 0 a 1 ao betweenness\n",
    "scaled_betweenness = [(b - min_betweenness) / (max_betweenness - min_betweenness) for b in betweenness]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f4b5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o tamanho dos nós com base no betweenness escalado e calcula os tamanhos dos nós com escala logarítmica\n",
    "gCitacaoBetweenness.vs[\"size\"] = [2.5 + 10 * b for b in scaled_betweenness]\n",
    "\n",
    "layout = gCitacaoBetweenness.layout_fruchterman_reingold()\n",
    "#plot(gCitacaoBetweenness, layout=layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1e6aa",
   "metadata": {},
   "source": [
    "## Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3440a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "gCitacaoDegree = gCitacao.copy()\n",
    "in_degrees = gCitacaoDegree.indegree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d4d129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degrees = gCitacaoDegree.indegree()\n",
    "\n",
    "# Defina o tamanho dos vértices com base nos graus de entrada usando log\n",
    "gCitacaoDegree.vs[\"size\"] = [math.log(in_degree) * 3 if in_degree > 0 else 0 for in_degree in in_degrees]\n",
    "\n",
    "layout = gCitacaoDegree.layout_fruchterman_reingold()\n",
    "#plot(gCitacao, layout=layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
